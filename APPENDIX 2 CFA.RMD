---
title: 'Appendix 2: Confirmatory factor analysis for general language measure'
author: "Paul Thompson"
date: "22 January 2018"
output: word_document
---

```{r setup, include=FALSE,warning=FALSE,message=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#install.packages(c("data.table","scales","lavaan"))
library(devtools) # to run script from gist and bring in data
library(lavaan)
library(semPlot)
library(knitr)
library(ggplot2)
library(reshape2)
library(psych)
library(xlsx)
require(tidyverse)
```


```{r,include=FALSE}
mydir<-"c:/Users/pthompson/Dropbox/project SCT analysis/data from redcap/old versions/"
sct.data<-read.csv(paste0(mydir,"SCTData_DATA_2017-10-02_1038.csv"))
twin.data<-read.csv(paste0(mydir,"TwinsData_DATA_2017-10-02_1037.csv"))

short.sct<-dplyr::select(sct.data,ï..record_id,age_at_test,wasi_matrices_ss,wasi_block_design_ss,wasi_vocab_ss,
                  wdck_jhsn_ss,sent_rep_ss,nonword_rep_ss,oromotor_ss,nara_acc_ss,nara_comp_ss,nara_rate_ss,
                  towre_words_ss,towre_nonwords_ss,phab_pic_ss,phab_digit_ss)
short.twin<-dplyr::select(twin.data,record_id,age_at_test,wasi_matrices_ss,wasi_block_design_ss,wasi_vocab_ss,
                  wdck_jhsn_ss,sent_rep_ss,nonword_rep_ss,oromotor_ss,nara_acc_ss,nara_comp_ss,nara_rate_ss,
                  towre_words_ss,towre_nonwords_ss,phab_pic_ss,phab_digit_ss)
short.sct$source<-'sct'
short.twin$source<-'twin'

names(short.sct)[1]<-"record_id"

all.data<-rbind(short.sct,short.twin)
all.data$source<-as.factor(all.data$source)


all.data$record_id<-as.factor(all.data$record_id)

for(i in 1:length(all.data))
{
  all.data[,i]<-car::recode(all.data[,i],"996=NA;997=NA;998=NA;999=NA")
}
data.f1<-all.data[,c(3:7,9:16)]

names(data.f1)<-c("matrices_ss", "blockD_ss","Vocab_ss", "WJ_ss", "Sent_Rep_ss",
 "Oro_ss", "Nara_acc", "Nara_comp", "Nara_rate", "Words_ss", 
 "Nwords_ss", "Pics_ss", "Digit_ss") 


```

#Confirmatory factor analysis for general language measure

A parallel analysis and scree plot were used to statistically determine whether multiple factors were present in the language and literacy data. The result indicated that two potential factors could be found on a purely statistical basis. Parallel analysis performs both factor and principal components, comparing the solutions for real and randomly resampled data from the real data to determine a more robust estimate of factors. Figure 2 shows the scree plot indicating two factors consistently.

```{r,fig.cap="Scree plot for Language and Literacy data",echo=FALSE,message=FALSE,warning=FALSE}
library(nFactors)

ev <- eigen(cor(data.f1,use= "na.or.complete")) # get eigenvalues
ap <- parallel(subject=nrow(data.f1),var=ncol(data.f1),
  rep=100,cent=.05)
nS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)
plotnScree(nS)

```

The language and literacy data fell naturally into two factors based on their content, giving reading and language factors. Two measures of non-verbal IQ (matrices and Block Design) were initially included into the language factor, but from a theoretical perspective made better sense to remove these and place into a separate factor, Non-verbal IQ. 
A confirmatory factor analysis was performed on the data to investigate the three factor solution using the R statistical software and the Lavaan package. 

```{r,warning=FALSE,include=FALSE}
library(lavaan)
model.f6 <- ' f1 =~ Vocab_ss + WJ_ss + Sent_Rep_ss + Oro_ss 
              f2 =~ Nara_acc + Nara_comp + Nara_rate + Words_ss + Nwords_ss + Pics_ss + Digit_ss
              f3 =~ matrices_ss + blockD_ss
              Nara_acc ~~ Nara_comp
              Pics_ss ~~ Digit_ss
              Vocab_ss ~~ WJ_ss'     
fit.mod.F <- cfa(model.f6, data = data.f1[-c(24,67),],estimator = "ML",missing = "ML")

lbls<-c("Vocab", "Woodcock\nJohnson", "Sentence\nRepetition", "Oromotor","NARA\nAccuracy","NARA\nComp","NARA\nRate","Towre\nWords","Towre\nNonwords","Phab\nPictures", "Phab\nDigits","WASI\nMatrices","WASI\nBlock D", "Language","Reading","Nonverbal\nIQ")
```
The model gives a  satisfactory fit to the data, but due to the high amount of missing data in reading factor, it was decide to focus on the language factor only. (χ2 (`r fitmeasures(fit.mod.F)[['df']]`) = `r round(fitmeasures(fit.mod.F)[['chisq']],3)`, p = `r round(fitmeasures(fit.mod.F)[['pvalue']],3)`, CFI = `r round(fitmeasures(fit.mod.F)[['cfi']],3)`, RMSEA = `r round(fitmeasures(fit.mod.F)[['rmsea']],3)` (90% CI `r round(fitmeasures(fit.mod.F)[['rmsea.ci.lower']],3)`–`r round(fitmeasures(fit.mod.F)[['rmsea.ci.upper']],3)`), SRMR = `r round(fitmeasures(fit.mod.F)[['srmr']],3)`.

```{r,fig.cap="Path diagram for full Confirmatory Factor Analysis (3 factor solution)",echo=FALSE}
semPaths(fit.mod.F, "std", title = TRUE,nodeLabels=lbls,intercepts = FALSE)
```

```{r,include=FALSE}
model.f5a <- ' f1 =~ Vocab_ss + WJ_ss + Sent_Rep_ss + Oro_ss 
              Vocab_ss ~~ WJ_ss'     
fit.mod.E2 <- cfa(model.f5a, data = data.f1,estimator = "ML",missing = "ML")

lbls<-c("Vocabulary", "Woodcock\nJohnson", "Sentence\nRepetition", "Oromotor","Language")
```

The amount of missing data in the reading factor was problematic and, so we re-ran the CFA with only the language factor, (χ2 (`r round(fitmeasures(fit.mod.E2)[['df']],3)`) = `r round(fitmeasures(fit.mod.E2)[['chisq']],3)`, p = `r round(fitmeasures(fit.mod.E2)[['pvalue']],3)`, CFI = `r round(fitmeasures(fit.mod.E2)[['cfi']],3)`, RMSEA = `r round(fitmeasures(fit.mod.E2)[['rmsea']],3)` (90% CI `r round(fitmeasures(fit.mod.E2)[['rmsea.ci.lower']],3)`–`r round(fitmeasures(fit.mod.E2)[['rmsea.ci.upper']],3)`), SRMR = `r round(fitmeasures(fit.mod.E2)[['srmr']],3)`). We also included a correlation term between vocabulary and Woodcock Johnson as suggested by Lavaan modification indices.


```{r,fig.cap="Path diagram for Confirmatory Factor Analysis (single language factor)",echo=FALSE}
semPaths(fit.mod.E2, "std", title = TRUE, curvePivot = TRUE, edge.label.cex = 1.2,width=10,height=5,nodeLabels=lbls,intercepts = FALSE,sizeMan = 10, sizeLat = 10)
```

Two children had no data for the raw language measures because their language was so limited that they could not attempt the tests. They were therefore assigned a score equivalent to the lowest score possible on the language tests. Factor scores were extracted for all children to be used as one of the phenotypic measures in the genetic association analysis.