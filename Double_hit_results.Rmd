---
title: 'Variation in neurodevelopmental outcomes: Results'
author: "Dianne F. Newbury, Nuala H. Simpson, Paul A. Thompson, Dorothy V. M. Bishop"
date: "17th June 2018"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#NB user should manually set working directory to source file location

require(doBy)
require(tidyverse)
require(lavaan)
require(yarrr) #for pirate plot
require(beanplot)
require(synthpop) #to create synthesised data for sharing
require(expss) #for fancy tables
#source("https://bioconductor.org/biocLite.R")
#biocLite("ASGSCA") #ASGSA is loaded via bioconductor
#see http://bioconductor.org/packages/release/bioc/html/ASGSCA.html

require(ASGSCA)
require(mtvnorm) #for simulating random normal data (avoids some problems arising with MASS)
require(MASS) #used to simulate data when getting expected p-values
library(knitr) #needed for kable
require(stargazer) #useful for tabular output
library(ggplot2)
library(grid)
library(gridExtra)
library(flextable)
library(officer)
```

```{r nperm, echo=FALSE}
mynperm <- 200 # Specify here N permutations for GSCA (see below)- will refer to this in the text.
#to test prog use 200 for speed; for final version altered to 5000 (takes several hrs to run)
run_GSCA <- 0 #Toggle this to 1 to run the GSCA. Option to suppress it here by setting to zero; useful when testing the script to avoid waiting for GSCA
do_GSCAk <-0 #Toggle for GSCA analysis by karyotype in doGSCAkary chunk
npsim <- 1000 #N simulations for checking distribution of obtained p-values vs expected - NB 1000 will run slowly
do_psim <-0 #Toggle to 1 to run the pvalue simulations
```

```{r readdi, echo=FALSE}
## Step 1
#Read in Di's datafile. 
#N.B. The data are pseudanonymised because individuals could be identified via rare SNPs. Consequently, these data not posted publicly. This section is for reference.

#First remove DB from ID, and _rpt, and for twins add A or B to the ID - new id column should match redcap record_id. Also delete original IID and FID cols. 
#Save this sheet as csv.

read.di.dir <- "~/Dropbox/ERCadvanced/project SCT analysis/SCT genetic analysis/snp raw data/"
di.file <- 'Di_imputed_SCT_twin.csv'
all.di <- read.csv(paste0(read.di.dir,di.file),stringsAsFactors = FALSE)
```



```{r readredcap, echo=FALSE}
## Step 2
#Read in latest SCT from redcap.
#Do the same for the twins.
#Select variables to be used.
redcap.dir <-"~/Dropbox/ERCadvanced/project SCT analysis/Data from Redcap/"
#Use latest version
sct.redcap <- 'SCTData_DATA_2018-01-22_1351.csv'
twin.redcap <- 'TwinsData_DATA_2018-01-22_1400.csv'
sct.data <- read.csv(paste0(redcap.dir,sct.redcap),stringsAsFactors = FALSE)
twin.data <- read.csv(paste0(redcap.dir,twin.redcap),stringsAsFactors = FALSE)
sct.data$rs7794745<-NA #add this for conformity with twin data
#fix any columns with discrepant names
w<-which(colnames(twin.data)=='neurodev_diagnosis')
colnames(twin.data)[w] <-'neurodev_diag'

twin.data$dyslexia<-twin.data$dld_rd%%10 #modulus 10 , ie last digit
twin.data$lang_disorder<-round((twin.data$dld_rd-4.5)/10) #first digit is dld code

#----------------------------------------------------------------------------------

keepcols <- c('record_id','age_at_test','partial_testing','wasi_matrices_ss','wasi_block_design_ss','wasi_vocab_ss','wdck_jhsn_ss',
              'sent_rep_ss','oromotor_ss','nonword_rep_ss','nara_acc_ss',      'nara_comp_ss','nara_rate_ss','towre_words_ss','towre_nonwords_ss','phab_pic_ss','phab_digit_ss','srs_t_score','gcc','scdi','slt','splang_conc','schooling','piq','neurodev_diag','dyslexia','lang_disorder',
              'hyperkinetic_icd_r1','adhd_comb_dsm_r1','adhd_hyp_dsm_r1','adhd_inatt_dsm_r1',
              'conduct_dsm_r1','asd_dsm_r1','autism_icd_r1','srs_t_score')

sct.short <- dplyr::select(sct.data,keepcols)
twin.short <-dplyr::select(twin.data,keepcols)
#----------------------------------------------------------------------------------
```


```{r combine, echo=FALSE}
#Add columns that are specific to twins or SCTs so all aligned
sct.short$TwinOrSCT <- 0 #this specifies child is not a twin but a trisomy
sct.short$zygosity <- NA
twin.short$TwinOrSCT <- twin.data$randomtwininclude+1 #twins subdivided
#randomly into 1 and 2 for replication sample
twin.short$zygosity <- twin.data$zygosity

sct.short$trisomy <- sct.data$trisomy
sct.short$pre_postnatal_diag <- sct.data$pre_postnatal_diag
sct.short$why_tested <-sct.data$why_tested
twin.short$trisomy <- NA
twin.short$pre_postnatal_diag <- NA
twin.short$why_tested <- NA
#----------------------------------------------------------------------------------
#Bolt SCT and twin files together
all.short <-rbind(sct.short,twin.short)

#----------------------------------------------------------------------------------
#Join columns for those that match the ones in all.di
# Inefficient but safe to do this in a loop
myvec <- vector()
for (i in 1:nrow(all.di)){
  myid <- all.di$ID[i]
  w <- which (all.short$record_id==myid)
  myvec <- c(myvec,w) #vector of rows in correct order
}
all.data <- cbind(all.di,all.short[myvec,])


```

```{r ncheck, echo=FALSE, include=FALSE}
#To include tables in document, include=TRUE
#Check that Ns match those in the protocol
#Should have twin groups with N = 184 and 186 (these are randomly assigned twin 1 and 2), and 130 SCT cases
twintab <- table(all.data$TwinOrSCT)
names(twintab)<-c('SCT','twin1','twin2')
twintab
scttab <- table(all.data$trisomy,all.data$why_tested)
#why tested coded as: 0, maternal age
# 1, medical concerns
# 2, behavioural concerns
# 3, neurodevelopmental concerns
# 4, family history of genetic problems
# 9, no information
biasgp<-scttab[10:12]#corresponds to value 3
nobiasgp <-rowSums(scttab)-biasgp #all others
fig2dat <-cbind(nobiasgp,biasgp)
rownames(fig2dat)<-c('XXX','XXY','XYY')
colnames(fig2dat)<-c('No bias','Bias')
fig2dat
```

```{r missingcheck, echo=FALSE, include=FALSE}
#Deal with missing data
#Check there is no missing data for the SNPs (16 values now imputed).
#Check for nonword rep - in some cases need to substitute low score, as unable to attempt task. 
#N.B. The process used to extract the language factor can handle missing data, so for measures used in that, we just substitute NA for values > 900.
w <- which(is.na(all.data[,2:48]))
paste('Cases with incomplete SNP data: ',all.data$record_id[w])

#missing data has codes of 996-999 for language tests
w <- which(all.data$nonword_rep_ss>900)
print('Cases with missing nonword rep data: ')
all.data$record_id[w]
#These cases all checked : all SCT cases who either were not tested because v limited spoken language, or who refused spoken tests or had low scores on other language tests. All these cases assigned a scaled score of 3.
all.data$nonword_rep_ss[w] <- 3

#999 is code where child was not tested bcs too low-functioning
w <- which(all.data$wasi_vocab_ss==999)
print('Cases with missing Vocab data (999) reassigned to floor: ')
all.data$record_id[w]
#These assigned SS of 2.33 SD below mean (equivalent to 3 on NEPSY scale)
all.data$wasi_vocab_ss[w] <- 25

w <- which(all.data$wdck_jhsn_ss==999)
print('Cases with missing Woodcock_J data (999) reassigned to floor: ')
all.data$record_id[w]
#These assigned SS of 2.33 SD below mean (equivalent to 3 on NEPSY scale)
all.data$wdck_jhsn_ss[w] <- 55

w <- which(all.data$sent_rep_ss==999)
print('Cases with missing Sent rep data (999) reassigned to floor:: ')
all.data$record_id[w]
#These assigned SS of 2.33 SD below mean (equivalent to 3 on NEPSY scale)
all.data$sent_rep_ss[w] <- 3

w <- which(all.data$oromotor_ss==999)
print('Cases with missing oromotor data (999) reassigned to floor:: ')
all.data$record_id[w]
#These assigned SS of 1 , as this corresponds to floor in this sample
all.data$oromotor_ss[w] <- 1

#Now substitute NA for any remaining > 900
mycols<-colnames(all.data)
mc <-which(mycols=='wasi_vocab_ss')
for (i in mc:(mc+3)){
w <- which(all.data[,i]>900)
all.data[w,i]<-NA

}
md <- which(is.na(all.data[,mc:(mc+3)]))
print(paste0(length(md),' missing values from ',nrow(all.data)*4,' datapoints in 4 language tests'))
```

```{r langfactor, echo=FALSE, include=FALSE}
#Compute language factor, using script from Appendix 2
library(lavaan)
library(semPlot)
model.f5a <- ' f1 =~ wasi_vocab_ss + wdck_jhsn_ss + sent_rep_ss + oromotor_ss 
              wasi_vocab_ss ~~ wdck_jhsn_ss'     
fit.mod.E2 <- cfa(model.f5a, data = all.data,estimator = "ML",missing = "ML")
lbls<-c("Vocabulary", "Woodcock\nJohnson", "Sentence\nRepetition", "Oromotor","Language")
semPaths(fit.mod.E2, "std", title = TRUE, curvePivot = TRUE, edge.label.cex = 1.2,width=10,height=5,nodeLabels=lbls,intercepts = FALSE,sizeMan = 10, sizeLat = 10)
all.data$langfactor <- predict(fit.mod.E2) #factor scores

```



```{r makeglobal, echo=FALSE}
#Create general neurodevelopmental index, using script from Appendix 3
# Our goal is to create a single scale reflecting global level of neurodevelopmental impairment. Data from initial parental telephone interview are available for all children. Data from language testing are available for all but two very low-functioning children, who were unable to attempt our tasks. Data from parental questionnaires (CCC-2 and SRS) and DAWBA DSM5 diagnoses are available for a subset. For SCT cases, questionnaire data were available for 127 out of 143 children, and DAWBA for 89 children. For comparison twin children, questionnaire data were available for 316 out of 388 children, and DAWBA for 276 children. We use all available data for each child to create a scale by adding points as follows:
# *History of speech problems = 1
# *Current help in mainstream school (support or special class or SLT) =1
# *Special school = 2
# *Dyslexia (test scores, unless no data , in which case report from parent interview) = 1
# *DLD (test scores, unless no data , in which case report from parent interview) = 1
# *ADHD (parental report or DAWBA diagnosis) = 1
# *Behaviour problems (DAWBA diagnosis of conduct disorder or clear description on interview) = 1
# *Autistic features: report from interview of definite diagnosis, or SRS = 90, or DAWBA diagnosis = 2
# *Low IQ (PIQ < 70 or refusal/inability to do battery - with exception of reading tests) = 1

# NB coding for slt is:
#0, never ; 1, preschool only; 2, beyond 4 yr; 3, ongoing; 8, assessed only; 9, no information

# Neurodev diagnosis codes:
# 0 none; others coded as all applicable from list:
#  1 ADHD, 2 APD, 3 ASD, 4 behav, 5 dyscalc, 6 dyslexia, 7 dyspraxia, 8  DLD/SLI/LD, 9 ID/GDD

#Lang dis from test scores; 0, no; 1, subclinical; 2, yes; 8, iq< 70; 9, no test results
#Dyslexia from test scors :0, no; 1, yes; 8, piq< 70; 9, no test results

#lang_concerns from parental report coded as splang_conc:
#0, never; 1, past; 2, continuing mild; 3, continuing severe; 9, unclear
#[for twins we also have code 4 if just concerns re reading; this is ignored here]

#SLT from parent report: 0, never; 1, preschool only; 2, beyond 4 yr; 3, ongoing; 8, assessed only; 9, no information

# School code
#1, mainstream no help; 2, mainstream with help; 3, special class/unit; 4, special school; 5, home schooled; 8, other; 9, dk

all.data$global_neurodev<-0 #Initialise to zero
w<-which(is.na(all.data$srs_t_score)) #Recode NA to 999 for SRS
all.data$srs_t_score[w]<-999

temp<-all.data$global_neurodev
w<-unique(which(all.data$slt==1),which(all.data$slt==8)) #Cases with preschool SLT or assessed by SLT
all.data$global_neurodev[w]<-all.data$global_neurodev[w]+1

#Now code so can add one point for help in mainstream or ongoing SLT or in language unit
w1<-c(which(all.data$schooling==2),which(all.data$schooling==3)) #help in mainstream/lang unit

all.data$global_neurodev[w1]<-all.data$global_neurodev[w1]+1

#add 2 points if attending special school
w<-which(all.data$schooling==4)
all.data$global_neurodev[w]<-all.data$global_neurodev[w]+1

#add 1 point if PIQ < 70 or not completed
w<-which(all.data$piq<70)
w1<-which(all.data$piq>996)
w2<-which(all.data$partial_testing>199) #failed to complete test battery (not because of age)
allw<-unique(w,w1,w2)
all.data$global_neurodev[allw]<-all.data$global_neurodev[allw]+1

## Next bits done in a loop because criteria not captured in a single code
nrows <-nrow(all.data)
for (i in 1:nrows){
  
  # add 1 to code if meets language test criteria for dyslexia OR (if no data) has diagnosis of this 
  # reported on parent interview
  wd<-NA
  temp<-all.data$dyslexia[i] #coding according to test battery, 1 if dyslexic
  if(temp==9){
    wd<-unlist(gregexpr(pattern ='6',toString(all.data$neurodev_diagnosis[i]))) #dyslexia code is 6
    #wd is one if 6 is included in neurodev_diag
  }
  if(length(wd)<1){temp=0}
  if (temp>0){all.data$global_neurodev[i]<-all.data$global_neurodev[i]+1}

#Add 1 to code if evidence of ADHD on parental interview or DAWBA
  w2<-unlist(gregexpr(pattern ='1',toString(all.data$neurodev_diagnosis[i]))) #ADHD code is 1
  if(w2==0){
  w2<-max(all.data$adhd_comb_dsm_r1[i],all.data$adhd_hyp_dsm_r1[i],all.data$adhd_inatt_dsm_r1[i])
  }
if (w2>0){all.data$global_neurodev[i]<-all.data$global_neurodev[i]+1}
  
# add 1 to code if meets language test criteria for lang_disorder OR (if no data) has diagnosis of this 
# reported on parent interview

temp<-all.data$lang_disorder[i] #coding according to test battery, 2 if with poor comp, 1 otherwise
w1<-temp
if(w1==2){w1<-1} #just one point added regardless of whether lang_dis code is 1 or 2
if(temp==9){ #no data on language tests so use parent interview
  w1<-unlist(gregexpr(pattern ='8',toString(all.data$neurodev_diagnosis[i]))) #DLD code is 8
  if(all.data$slt[i]==3){w1<-1} #regardless of diagnosis, ongoing SLT counts as DLD
  if(all.data$splang_conc[i]==3){w1<-1}#also serious language concerns count as DLD
} 
if (w1>0){all.data$global_neurodev[i]<-all.data$global_neurodev[i]+w1}
#NB more severe language problems with poor comprehension get addition of 2 points

# add 1 to code if significant behaviour problems on interview or DAWBA

  w1<-unlist(gregexpr(pattern ='4',toString(all.data$neurodev_diagnosis[i]))) #behav problems code is 4
  w2<-all.data$conduct_dsm_r1[i]
if (is.na(w2)){w2<-0}
  if (max(w1,w2)>0){all.data$global_neurodev[i]<-all.data$global_neurodev[i]+1}
  
# add 2 to code if ASD on interview or DAWBA or SRS is 90 or more

w1<-unlist(gregexpr(pattern ='3',toString(all.data$neurodev_diagnosis[i]))) #ASD code is 3
w2<-all.data$asd_dsm_r1[i]
if(is.na(w2)){w2<-0}
w3<-0

if(all.data$srs_t_score[i]>89) {w3<-1} #SRS t score 90

     if(all.data$srs_t_score[i]>900){w3<-0} 
if (max(w1,w2,w3)>0){all.data$global_neurodev[i]<-all.data$global_neurodev[i]+2}
#vertically jittered data created so all points visible on plot
all.data$global_neurodev[i]<-8-all.data$global_neurodev[i] #rescale so high is good
all.data$global_jittered[i]<-all.data$global_neurodev[i]+.5*runif(1)-.25
all.data$nonword_rep_jittered[i]<-all.data$nonword_rep_ss[i]+.5*runif(1)-.25
}
```
```{r computecorr, echo=FALSE}
#compute correlation between the 3 phenotypes
phencols<-which(colnames(all.data)%in%c('nonword_rep_ss','langfactor','global_neurodev')) #find the columns corresponding to phenotypes
phendat<-all.data[,phencols]
phencor <- data.frame(cor(phendat))
#compute correlation between the SNPs
gencor <-data.frame(cor(all.data[,2:48]))
#We can use these correlations in simulation to find out expected distribution of p-values
#if no pheno-geno correlation - see simnull below

```
##Results
Figure 5 shows the distributions of scores on the three phenotypes for children with sex chromosome trisomies and the two comparison groups. The scores for Global burden are inverted so a low score corresponds to impairment, to be consistent with the other two measures, and scores on Global burden and Nonword repetition are jittered vertically for clarity. Phenotypic characteristics of children with SCTs will be the focus of a separate publication, but we may note that, as anticipated, the group with SCTs show evidence of impairment on all three phenotype measures, but with a wide range of scores. For the combined sample with all cases (N = `r nrow(phendat)`), the three phenotype measures were intercorrelated: Nonword repetition correlated `r round(phencor[1,2],2)` with the language factor, and `r round(phencor[1,3],2)` with the global impairment rating. The language factor and global impairment rating correlated `r round(phencor[2,3],2)`.

```{r beanplot, fig.width=15,fig.height=6,fig.cap="Figure 5", echo=FALSE}
##Plot phenotypes for 3 groups
#Originally for inline figure used beanplot as this allows a loop whereas pirateplot does not.
#This now obsolete so made optional (code retained for interest)
dobeanplot <- 0 #determines whether beanplots are plotted or not; 1 to plot
all.data$langfactor <- as.numeric(all.data$langfactor)
par(mfrow=c(1,3))

  all.data$TwinOrSCT <- as.factor(all.data$TwinOrSCT)
   levels(all.data$TwinOrSCT)<- c('SCT','Twin1','Twin2') #ensures correct labels for axis
  mypheno <- c('Language factor','Global burden (inverted)','Nonword repetition')
  mycol<-which(colnames(all.data)%in%c('nonword_rep_jittered','langfactor','global_jittered')) #find the columns corresponding to phenotypes

  colnames(all.data)[mycol] #check we have correct variables
  myylim <- matrix(c(-30,30,0,20,-10,25),nrow=3,byrow=TRUE)
  if (dobeanplot == 1){
  for (i in 1:3){
  beanplot(all.data[,mycol[i]]~ all.data$TwinOrSCT,
           col='lightgray',
            point.o = .5,
            bar.f.o=.0,
            inf.f.o=.2,
            bean.b.o=.5,
            jitter=.1,
            ylab=mypheno[i],
           ylim=c(myylim[i,1],myylim[i,2]),
            main=paste0(mypheno[i]),
                  data=all.data
           )
  }
  }

```

```{r pngpirate, echo=FALSE}
#Make png with 3 pirate plots. Plot will be saved to working directory and picked up by rmd command
png(filename="pirate_fig5.png", 
    units="in", 
    width=6, 
    height=3, 
    pointsize=10, 
    res=300) #these settings give high resolution
par(mfrow=c(1,3)) #one row and three cols
  myylim <- matrix(c(-30,30,0,20,-10,25),nrow=3,byrow=TRUE) #y axis range differs for each phenotype
 
  pirateplot(formula=nonword_rep_jittered~ TwinOrSCT ,
             data=all.data,ylab=mypheno[3],xlab='',
           ylim=c(0,20),point.o=.6,inf.f.o=0,inf.b.o=0,cex.lab=1.2)
  pirateplot(formula=langfactor~ TwinOrSCT ,
             data=all.data,ylab=mypheno[1],xlab='',
           ylim=c(-30,30),point.o=.6,inf.f.o=0,inf.b.o=0,cex.lab=1.2)
  pirateplot(formula=global_jittered~ TwinOrSCT ,
             data=all.data,ylab=mypheno[2],xlab='',
           ylim=c(0,10),jitter.val=.065,point.o=.6,inf.f.o=0,inf.b.o=0,cex.lab=1.2)
  
par(mfrow=c(1,1)) #turn off split screen

dev.off() #stop printing to png
```

![*Figure 5: Pirate plots (Phillips, 2017) for SCT and two twin groups,  showing individual cases as points, with bold line depicting median, for Nonword repetition (scaled score), Language factor and Global neurodevelopmental impairment (inverted so low score reflects impairment).*](pirate_fig5.png)


##GSCA path-fitting analysis
Data from the three phenotypes were fitted using the model in Figure 4, first for the SCT group, and then separately for the two comparison groups. P-values were based on `r mynperm` permutations. The association with the 'Neurodev' factor did not meet our criterion for significance for either NRXN1 nor CNTNAP2 (see Table 2). 

```{r runGSCA,echo=FALSE}

if (run_GSCA==1){ #this variable set at start of script; can be zero to skip this chunk
#Run GSCA on each of the 3 groups


options(scipen = 999) #turn off scientific notation
allfit<-data.frame(matrix(0,3,3))  #make data table to save p-values
colnames(allfit)<-c('Group','NRXN1 p-value','CNTNAP2 p-value')
#previously saved paths here too, but they aren't interpretable so better to omit

thisgroup <- 0 #SCT
groupname <-c('SCT','Twin1','Twin2')

for (thisgroup in 1:3){
print(groupname[thisgroup])
w <- which(all.data$TwinOrSCT==levels(all.data$TwinOrSCT)[thisgroup])

mysample <- all.data[w,c(2:48,phencols)]

ObservedVar=colnames(mysample)
LatentVar=c("NRXN","CNTNAP2","Neurodev")
#first 23 SNPs are from NRXN and next lot from CNTNAP2
#W0 is I x L matrix where rows are genotypes and traits, columns are genes and latent phenotype
W0=matrix(rep(0,3*length(mysample)),nrow=length(mysample),ncol=3, dimnames=list(ObservedVar,LatentVar))
W0[1:23,1]=W0[24:47,2]=W0[48:50,3]=1

#B0 is L x L matrix with 0s and 1s, where 1 indicates arrow from latent geno in row to latent phenotype in column
B0=matrix(rep(0,3*3),nrow=3,ncol=3, dimnames=list(LatentVar,LatentVar))
B0[1,3]=1
B0[2,3]=1

 myfit<-GSCA(mysample,W0, B0,latent.names=LatentVar, estim=TRUE,path.test=TRUE,path=NULL,nperm=mynperm)

#print(myfit) #Prints full fit from just this run through loop
allfit[thisgroup,1]<-groupname[thisgroup]
allfit[thisgroup,2]<-myfit$pvalues[1,3]
allfit[thisgroup,3]<-myfit$pvalues[2,3]
}
kable(allfit,caption='Table 2. P-values from 5000 permutations for association with neurodevelopmental factor for NRXN1 and CNTNAP2: results from GSCA analysis')
}
```


##Additional exploratory analyses
Further exploratory analyses were conducted to rule out the possibility that our analytic approach may have missed significant associations with specific SNPs. Appendix 8 shows associations computed for all the individual SNPs entered into the analysis. The distribution of p-values seen for the whole collection of SNPs did not differ from that expected by chance. Finally, Figure 6 shows how number of minor alleles relates to phenotype for the two SNPs in CNTNAP2 (rs2010102 and rs7794745) that have been a particular focus of research attention. 

![*Figure 6: Mean (SE) scores for three groups for Nonword repetition (scaled score), Language factor and Global neurodevelopmental impairment (inverted so low score reflects impairment)*](SNPS_fig6.png)

###Appendix 8
##Association of individual SNPs/phenotypes
NB with a total of 3 tests for each of 47 SNPs, there are 141 tests; Bonferroni corrected p-value is .0003. See below for distribution of p-values, none of which was less than the Bonferroni-corrected value.
Each column corresponds to one SNP. The first block shows results for the SCT group, then twin subsample A (TWA), then twin subsample B (TWB). The initial rows show the N cases with 0, 1 or 2 copies of the minor allele. This is followed by values for the regression slope (b) and the p-value (p) for each of the phenotypes (nonword repetition = nwd; language factor = lang; global neurodevelopmental = global).


```{r manyregs, echo=FALSE}
##Check regression of each SNP on each pheno for each group

pmatrix <- data.frame(matrix(NA,47,10))
bmatrix <-data.frame(pmatrix)
   for (s in 2:48){
     pmatrix[(s-1),1] <- colnames(all.data)[s]
     thiscol <-1
     for (g in 1:3){
       thiscol <-thiscol+1
        for (p in 1:3){
        if (p>1) {thiscol <-thiscol+1}
     w <- which(all.data$TwinOrSCT==levels(all.data$TwinOrSCT)[g])
     mysample <- all.data[w,c(s,phencols[p])]
     colnames(mysample)<-c('x','y')
     myfit<- lm(y ~ x , data=mysample)
     pmatrix[(s-1),thiscol] <- summary(myfit)$coefficients[2,4] 
     bmatrix[(s-1),thiscol]<- paste(round(summary(myfit)$coefficients[2,1],2),'\u00B1', round(summary(myfit)$coefficients[2,2],2))
     colnames(pmatrix)[thiscol]<-paste0('G',g,'_Ph',p)
    }
  }
   }
write.csv(pmatrix,'p_value_matrix.csv')
```


```{R SNPsummary, echo=FALSE}
#redo as correlation matrix
checkcor <- data.frame(cor(all.data[,2:48]))
write_csv(checkcor,'mycheckcor.csv')

sumtable <- data.frame(matrix(0,47,28)) #create table to summarize freqs of SNPs, with beta and p-values by group and SNP
colnames(sumtable)<-c('SNP','SCT0','SCT1','SCT2','SCT_nwd_b','SCT_nwd_p','SCT_lang_b','SCT_lang_p','SCT_global_b','SCT_global_p',
        'TWA0','TWA1','TWA2','TWA_nwd_b','TWA_nwd_p','TWA_lang_b','TWA_lang_p','TWA_global_b','TWA_global_p',
         'TWB0','TWB1','TWB2','TWB_nwd_b','TWB_nwd_p','TWB_lang_b','TWB_lang_p','TWB_global_b','TWB_global_p')
for (ii in 2:48){
  thist <- table(all.data$TwinOrSCT,all.data[,ii])
  sumtable[(ii-1),2:4]<-thist[c(1,4,7)]
  sumtable[(ii-1),11:13]<-thist[c(2,5,8)]
  sumtable[(ii-1),20:22]<-thist[c(3,6,9)]
  sumtable[(ii-1),1]<-colnames(all.data)[ii]
}
  sumtable[,c(5,7,9)]<-bmatrix[,2:4] #b values for group SCT, 3 phenos
  sumtable[,c(6,8,10)]<-round(pmatrix[,2:4],3) #p values for group SCT, 3 phenos
  sumtable[,c(14,16,18)]<-bmatrix[,5:7] #b values for group twinA, 3 phenos
  sumtable[,c(15,17,19)]<-round(pmatrix[,5:7],3) #p values for group twinA, 3 phenos
  sumtable[,c(23,25,27)]<-bmatrix[,8:10] #b values for group SCT, 3 phenos
  sumtable[,c(24,26,28)]<-round(pmatrix[,8:10],3) #p values for group SCT, 3 phenos
write_csv(sumtable,'SNPsummary.csv')
#break into tables that will print on A4 and transpose
sumtab1<-t(sumtable[1:6,])#NRXN1 
sumtab2<-t(sumtable[12:17,]) 
sumtab3<-t(sumtable[18:23,])
sumtab4<-t(sumtable[24:30,]) #CNTNAP2 
sumtab5<-t(sumtable[31:36,])
sumtab6<-t(sumtable[37:42,]) 
sumtab7<-t(sumtable[43:47,]) 
print('NRXN1 SNPs')
kable(sumtab1)
kable(sumtab2)
kable(sumtab3)
print('CNTNAP2 SNPs')
kable(sumtab4)
kable(sumtab5)
kable(sumtab6)
kable(sumtab7)

#Trying flextable, but this is going to need more work: loses row/col names!
# print('NRXN1 SNPs')
# flextable::regulartable(data.frame(sumtab1))
# flextable::regulartable(data.frame(sumtab2))
# flextable::regulartable(data.frame(sumtab3))
# print('CNTNAP2 SNPs')
# flextable::regulartable(data.frame(sumtab4))
# flextable::regulartable(data.frame(sumtab5))
# flextable::regulartable(data.frame(sumtab6))
# flextable::regulartable(data.frame(sumtab7))


```

##P-value histograms
Histograms were used to compare observed distribution of p-values with that expected by chance, taking into account the correlations within the SNP set and the correlations between phenotypes. It is clear from inspection that the distribution of p-values is compatible with there being no association between SNPs and phenotypes.
```{r simnull, echo=FALSE}
#Simulate data assuming no geno-pheno correlation
# We predict a rectangular distribution of p-values, but doing it this way means we
# can consider if there is any impact of correlations within genos and phenos
#First specify covariance matrix for simulation
if (do_psim==1){
nVar<-length(phencor)+length(gencor)
myCov<-data.frame(matrix(rep(0,nVar*nVar),nrow=nVar)) #initialise covariance matrix
colnames(myCov)<-c(colnames(phencor),colnames(gencor))
diag(myCov)<-rep(1,nVar) # put one on the diagonals.
#upper left hand corner of matrix has phencor
myCov[1:3,1:3]<-phencor
#upper left hand corner of matrix has gencor
myCov[4:50,4:50]<-gencor
#Now we create simulated data using existing correlations within geno and phenotypes 
#but with no correlation between geno and pheno
nPop <- 10000 #large base population from which we will repeatedly sample
mydatanull <- mvrnorm(n = nPop,rep(0,nVar), myCov) #mean 0 and SD 1 for all variables
#simulate a sample of 185: given that only comparison sample has any hint of association
myN <- 185
nullp <- vector() #set up vector to hold all p-values
npsim <- 1000 #N simulations - need lots to get accurate p-distribution estimate
             #but can test program with a small number
for (j in 1:npsim){
  thissample <- sample(nPop,myN) #select a random myN from the big population
  for (i in 1:3){ #cycle through phenotypes
    for (k in 4:50) {#cycle through SNPs
      x <- mydatanull[thissample,k]
      y <- mydatanull[thissample,i] 
      myfit<- lm(y ~ x )
     nullp <- c(nullp,summary(myfit)$coefficients[2,4] )
    }
  }
}
#Plot the distribution of p-values for null situation and both twin groups
png(filename="histo_pvals.png", 
    units="in", 
    width=5, 
    height=4, 
    pointsize=10, 
    res=300)
par(mfrow=c(2,2))
hist(nullp, breaks=40,xlab='p-value',ylab='Freq',main='Simulated with null effect')
obsp.sct <- c(pmatrix[,2],pmatrix[,3],pmatrix[,4])
hist(obsp.sct,breaks=40,xlab='p-value',ylab='Freq',main='SCT group: observed p-values')
obsp.twinA <- c(pmatrix[,5],pmatrix[,6],pmatrix[,7])
hist(obsp.twinA,breaks=40,xlab='p-value',ylab='Freq',main='Twin A: observed p-values')
obsp.twinB <- c(pmatrix[,8],pmatrix[,9],pmatrix[,10])
hist(obsp.twinB,breaks=40,xlab='p-value',ylab='Freq',main='Twin B: observed p-values')
dev.off()
}
```


```{r reducedset,echo=FALSE}
#A couple of alternative runs of GSCA just to check whether atypical SNPs affect results.
# 1. Try redoing after omitting those with no homozygous rare allele
doreduce=0 #to avoid slowing down knitr, make this optional - results are unexciting!
#Confirms this is not masking interesting effects
if (doreduce==1){
  ww<-1+which(sumtable[,4]>-1) #all with some numeric values
for (thisgroup in 1:3){
print(groupname[thisgroup])
w <- which(all.data$TwinOrSCT==levels(all.data$TwinOrSCT)[thisgroup])

mysample2 <- all.data[w,c(ww,phencols)]
#range is now 1:13 for nrxn and 14:27 for cntnap2
ObservedVar=colnames(mysample2)
LatentVar=c("NRXN","CNTNAP2","Neurodev")
#W0 is I x L matrix where rows are genotypes and traits, columns are genes and latent phenotype
W0=matrix(rep(0,3*length(mysample2)),nrow=length(mysample2),ncol=3, dimnames=list(ObservedVar,LatentVar))
W0[1:18,1]=W0[19:37,2]=W0[38:40,3]=1

#B0 is L x L matrix with 0s and 1s, where 1 indicates arrow from latent geno in row to latent phenotype in column
B0=matrix(rep(0,3*3),nrow=3,ncol=3, dimnames=list(LatentVar,LatentVar))
B0[1,3]=1
B0[2,3]=1

 myfit<-GSCA(mysample2,W0, B0,latent.names=LatentVar, estim=TRUE,path.test=TRUE,path=NULL,nperm=mynperm)

print(myfit)
}
}
```
```{r reducedset2, echo=FALSE}
#2. Do high intercorrelations between SNPs affect GCSA?
# Try redoing after omitting those that correlate > .9 with another SNP
doreduce2=0 #again, this is optional, and just here for completeness, as it does not have much impact
if (doreduce2==1){
  mynperm=100 
mykeep <-vector()
for (i in 1:47){
ww<-which(checkcor[i,]>.9) #this one has a high correlation
if(length(ww)==1){mykeep <-c(mykeep,i)}}
for (thisgroup in 1:3){
print(groupname[thisgroup])
w <- which(all.data$TwinOrSCT==levels(all.data$TwinOrSCT)[thisgroup])

mysample3 <- all.data[w,c(mykeep,phencols)]
#range is now 1:12 for nrxn and 13:37 for cntnap2
ObservedVar=colnames(mysample3)
LatentVar=c("NRXN","CNTNAP2","Neurodev")
#W0 is I x L matrix where rows are genotypes and traits, columns are genes and latent phenotype
W0=matrix(rep(0,3*length(mysample3)),nrow=length(mysample3),ncol=3, dimnames=list(ObservedVar,LatentVar))
W0[1:12,1]=W0[13:27,2]=W0[28:30,3]=1

#B0 is L x L matrix with 0s and 1s, where 1 indicates arrow from latent geno in row to latent phenotype in column
B0=matrix(rep(0,3*3),nrow=3,ncol=3, dimnames=list(LatentVar,LatentVar))
B0[1,3]=1
B0[2,3]=1

 myfit<-GSCA(mysample3,W0, B0,latent.names=LatentVar, estim=TRUE,path.test=TRUE,path=NULL,nperm=mynperm)

print(myfit)
}
}
```

##Comparison of karyotypes
In addition, we followed up suggestions by Skuse (2018) that results may vary by karyotype, because the expression of NLGN4X is variable, whereas in males with XYY, NLGN4Y is fully expressed. Accordingly, one might expect a more severe impact of a double hit in the XYY group. To test this, we reran the GSCA separately for XXX, XXY and XYY subsamples, restricting consideration to those who were diagnosed prenatally, as specified in our protocol. As shown in Table 3, there was no hint of any association between genotype and phenotype in these subgroups.  Note, however, as we originally noted, this analysis has very low power to detect true effects.
```{r GSCAkary,echo=FALSE}

#Run GSCA on each of the 3 karyotypes
#NB restrict to prenatally-diagnosed, ie pre_postnatal_diag==1
if (do_GSCAk == 1){
options(scipen = 999) #turn off scientific notation
allfit<-data.frame(matrix(0,3,3))  #make data table to save results
colnames(allfit)<-c('Group','NRXN1 p-value','CNTNAP2 p-value')

thisgroup <- 0 #SCT
groupname <-c('XXX','XXY','XYY')

unbiased<-filter(all.data,why_tested!=3)
for (thisgroup in 1:3){
print(groupname[thisgroup])
w <- which(unbiased$trisomy==thisgroup)

mysample <- unbiased[w,c(2:48,phencols)]


#With this reduced sample size, some SNPs have zeroes for all cases - need to exclude these
coltots <-colSums(mysample[,1:47])
wc <- which(coltots==0)
if (length(wc)>0){
mysample <- mysample[,-wc]
}
n1 <-length(which(wc<24))
n2 <- length(which(wc>23))
range1 <- 1:23
range2 <-24: 47
range3 <-48:50

  range1 <- 1:(max(range1)-n1)
  range2 <-(1+max(range1)):(max(range1)+24-n2)
  range3 <-(1+max(range2)):(max(range2)+3)
  ObservedVar=colnames(mysample)
LatentVar=c("NRXN","CNTNAP2","Neurodev")
#first 23 SNPs are from NRXN and next lot from CNTNAP2
#W0 is I x L matrix where rows are genotypes and traits, columns are genes and latent phenotype
W0=matrix(rep(0,3*length(mysample)),nrow=length(mysample),ncol=3, dimnames=list(ObservedVar,LatentVar))
W0[range1,1]=W0[range2,2]=W0[range3,3]=1

#B0 is L x L matrix with 0s and 1s, where 1 indicates arrow from latent geno in row to latent phenotype in column
B0=matrix(rep(0,3*3),nrow=3,ncol=3, dimnames=list(LatentVar,LatentVar))
B0[1,3]=1
B0[2,3]=1

 myfit<-GSCA(mysample,W0, B0,latent.names=LatentVar, estim=TRUE,path.test=TRUE,path=NULL,nperm=mynperm)

#print(myfit)
allfit[thisgroup,1]<-paste(groupname[thisgroup], 'N = ',nrow(mysample))
allfit[thisgroup,2]<-myfit$pvalues[1,3]
allfit[thisgroup,3]<-myfit$pvalues[2,3]
}
kable(allfit,caption='Table 3. P-values based on 5000 permutations for association with neurodevelopmental factor for NRXN1 and CNTNAP2 for SCT cases subdivided by karyotype, excluding those identified because of neurodevelopmental problems: results from GSCA analysis.')
}
```

```{R snpmeansplot, echo=FALSE}

#Plots of mean by N alleles for 2 SNPs with prior evidence of links to language

t2<-summaryBy( nonword_rep_ss~  TwinOrSCT+rs7794745imp_T, data = all.data,
  FUN = function(x) { c(n=length(x),m = mean(x), se = sd(x)/sqrt(length(x))) } )

t2$phenotype<-rep("nonword_rep_ss",9)
t2$SNP<-rep(colnames(t2)[2],9)
colnames(t2)[1:5]<-c("Group","Genotype","N","Mean","SE")


t3<-summaryBy( nonword_rep_ss~  TwinOrSCT+rs2710102imp_G, data = all.data,
  FUN = function(x) { c(n=length(x),m = mean(x), se = sd(x)/sqrt(length(x))) } )

t3$phenotype<-rep("nonword_rep_ss",9)
t3$SNP<-rep(colnames(t3)[2],9)
colnames(t3)[1:5]<-c("Group","Genotype","N","Mean","SE")


t5<-summaryBy(langfactor~  TwinOrSCT+rs7794745imp_T, data = all.data,
  FUN = function(x) { c(n=length(x),m = mean(x), se = sd(x)/sqrt(length(x))) } )

t5$phenotype<-rep("langfactor",9)
t5$SNP<-rep(colnames(t5)[2],9)
colnames(t5)[1:5]<-c("Group","Genotype","N","Mean","SE")

t6<-summaryBy( langfactor~  TwinOrSCT+rs2710102imp_G, data = all.data,
  FUN = function(x) { c(n=length(x),m = mean(x), se = sd(x)/sqrt(length(x)))} )

t6$phenotype<-rep("langfactor",9)
t6$SNP<-rep(colnames(t6)[2],9)
colnames(t6)[1:5]<-c("Group","Genotype","N","Mean","SE")

t8<-summaryBy(global_neurodev~  TwinOrSCT+rs7794745imp_T, data = all.data,
  FUN = function(x) { c(n=length(x),m = mean(x), se = sd(x)/sqrt(length(x))) } )

t8$phenotype<-rep("global_neurodev",9)
t8$SNP<-rep(colnames(t8)[2],9)
colnames(t8)[1:5]<-c("Group","Genotype","N","Mean","SE")


t9<-summaryBy( global_neurodev~  TwinOrSCT+rs2710102imp_G, data = all.data,
  FUN = function(x) { c(n=length(x),m = mean(x), se = sd(x)/sqrt(length(x))) } )

t9$phenotype<-rep("global_neurodev",9)
t9$SNP<-rep(colnames(t9)[2],9)
colnames(t9)[1:5]<-c("Group","Genotype","N","Mean","SE")

plot.dat<-rbind(t2,t3)
plot.dat<-rbind(plot.dat,t5)
plot.dat<-rbind(plot.dat,t6)
plot.dat<-rbind(plot.dat,t8)
plot.dat<-rbind(plot.dat,t9)

plot.dat$Group<-as.factor(plot.dat$Group)
plot.dat$phenotype<-as.factor(plot.dat$phenotype)
plot.dat$SNP<-as.factor(plot.dat$SNP)
levels(plot.dat$SNP)<-c("rs2710102", "rs7794745")
levels(plot.dat$phenotype)<-c('Global Neurodev', 'Language Factor', 'Nonword Repetition')


plot.dat1 <- plot.dat[plot.dat$phenotype=="Global Neurodev",]
plot.dat2 <- plot.dat[plot.dat$phenotype=="Language Factor",]
plot.dat3 <- plot.dat[plot.dat$phenotype=="Nonword Repetition",]

png(filename="SNPS_fig6.png", 
    units="in", 
    width=6, 
    height=3, 
    pointsize=10, 
    res=300) #these settings give high resolution

p1<-ggplot(plot.dat1,aes(x=Genotype,y=Mean,group=Group,colour= Group))+geom_line()+geom_point(aes(shape = Group))+geom_errorbar(aes(ymin=Mean-SE, ymax=Mean+SE), width=.2,
                 position=position_dodge(0.1))+facet_grid(SNP~phenotype)+theme_bw()+theme(legend.position="bottom",text = element_text(size=12),
  strip.text.y = element_blank())+ scale_x_continuous(breaks=seq(0,2,1))+xlab(" ")

p2<-ggplot(plot.dat2,aes(x=Genotype,y=Mean,group=Group,colour= Group))+geom_line()+geom_point(aes(shape = Group))+geom_errorbar(aes(ymin=Mean-SE, ymax=Mean+SE), width=.2,
                 position=position_dodge(0.1))+facet_grid(SNP~phenotype)+theme_bw()+theme(legend.position="bottom",text = element_text(size=12),
  strip.text.y = element_blank(),axis.title.y=element_blank())+ scale_x_continuous(breaks=seq(0,2,1))+xlab("N. minor alleles")

p3<-ggplot(plot.dat3,aes(x=Genotype,y=Mean,group=Group,colour= Group))+geom_line()+geom_point(aes(shape = Group))+geom_errorbar(aes(ymin=Mean-SE, ymax=Mean+SE), width=.2,
                 position=position_dodge(0.1))+facet_grid(SNP~phenotype)+theme_bw()+theme(legend.position="bottom",text = element_text(size=12),axis.title.y=element_blank())+ scale_x_continuous(breaks=seq(0,2,1))+xlab(" ")

grid.arrange(p1, p2, p3, nrow = 1)

grid_arrange_shared_legend <- function(..., ncol = length(list(...)), nrow = 1, position = c("bottom", "right")) {

  plots <- list(...)
  position <- match.arg(position)
  g <- ggplotGrob(plots[[1]] + theme(legend.position = position))$grobs
  legend <- g[[which(sapply(g, function(x) x$name) == "guide-box")]]
  lheight <- sum(legend$height)
  lwidth <- sum(legend$width)
  gl <- lapply(plots, function(x) x + theme(legend.position="none"))
  gl <- c(gl, ncol = ncol, nrow = nrow)

  combined <- switch(position,
                     "bottom" = arrangeGrob(do.call(arrangeGrob, gl),
                                            legend,
                                            ncol = 1,
                                            heights = unit.c(unit(1, "npc") - lheight, lheight)),
                     "right" = arrangeGrob(do.call(arrangeGrob, gl),
                                           legend,
                                           ncol = 2,
                                           widths = unit.c(unit(1, "npc") - lwidth, lwidth)))

  grid.newpage()
  grid.draw(combined)

  # return gtable invisibly
  invisible(combined)

}

grid_arrange_shared_legend(p1, p2, p3, nrow = 1)
dev.off() #stop sending output to png

```

```{R snpmeansbykaryplot, echo=FALSE}

#Plots of mean by N alleles for 2 SNPs with prior evidence of links to language
#This time just SCTs divided by karyotype - v. noisy data - no hint of selective effect of XYY. This is just for legacy. Not for report.

t2<-summaryBy( nonword_rep_ss~  trisomy+rs7794745imp_T, data = all.data[1:130,],
  FUN = function(x) { c(n=length(x),m = mean(x), se = sd(x)/sqrt(length(x))) } )

t2$phenotype<-rep("nonword_rep_ss",9)
t2$SNP<-rep(colnames(t2)[2],9)
colnames(t2)[1:5]<-c("Trisomy","Genotype","N","Mean","SE")


t3<-summaryBy( nonword_rep_ss~  trisomy+rs2710102imp_G, data = all.data[1:130,],
  FUN = function(x) { c(n=length(x),m = mean(x), se = sd(x)/sqrt(length(x))) } )

t3$phenotype<-rep("nonword_rep_ss",9)
t3$SNP<-rep(colnames(t3)[2],9)
colnames(t3)[1:5]<-c("Trisomy","Genotype","N","Mean","SE")


t5<-summaryBy(langfactor~  trisomy+rs7794745imp_T, data = all.data[1:130,],
  FUN = function(x) { c(n=length(x),m = mean(x), se = sd(x)/sqrt(length(x))) } )

t5$phenotype<-rep("langfactor",9)
t5$SNP<-rep(colnames(t5)[2],9)
colnames(t5)[1:5]<-c("Trisomy","Genotype","N","Mean","SE")

t6<-summaryBy( langfactor~  trisomy+rs2710102imp_G, data = all.data[1:130,],
  FUN = function(x) { c(n=length(x),m = mean(x), se = sd(x)/sqrt(length(x)))} )

t6$phenotype<-rep("langfactor",9)
t6$SNP<-rep(colnames(t6)[2],9)
colnames(t6)[1:5]<-c("Trisomy","Genotype","N","Mean","SE")

t8<-summaryBy(global_neurodev~  trisomy+rs7794745imp_T, data = all.data[1:130,],
  FUN = function(x) { c(n=length(x),m = mean(x), se = sd(x)/sqrt(length(x))) } )

t8$phenotype<-rep("global_neurodev",9)
t8$SNP<-rep(colnames(t8)[2],9)
colnames(t8)[1:5]<-c("Trisomy","Genotype","N","Mean","SE")


t9<-summaryBy( global_neurodev~  trisomy+rs2710102imp_G, data = all.data[1:130,],
  FUN = function(x) { c(n=length(x),m = mean(x), se = sd(x)/sqrt(length(x))) } )

t9$phenotype<-rep("global_neurodev",9)
t9$SNP<-rep(colnames(t9)[2],9)
colnames(t9)[1:5]<-c("Trisomy","Genotype","N","Mean","SE")

plot.dat<-rbind(t2,t3)
plot.dat<-rbind(plot.dat,t5)
plot.dat<-rbind(plot.dat,t6)
plot.dat<-rbind(plot.dat,t8)
plot.dat<-rbind(plot.dat,t9)

plot.dat$Trisomy<-as.factor(plot.dat$Trisomy)
plot.dat$phenotype<-as.factor(plot.dat$phenotype)
plot.dat$SNP<-as.factor(plot.dat$SNP)
levels(plot.dat$SNP)<-c("rs2710102", "rs7794745")
levels(plot.dat$phenotype)<-c('Global Neurodev', 'Language Factor', 'Nonword Repetition')


plot.dat1 <- plot.dat[plot.dat$phenotype=="Global Neurodev",]
plot.dat2 <- plot.dat[plot.dat$phenotype=="Language Factor",]
plot.dat3 <- plot.dat[plot.dat$phenotype=="Nonword Repetition",]

png(filename="SNPS_bytrisomy_fig7.png", 
    units="in", 
    width=6, 
    height=3, 
    pointsize=10, 
    res=300) #these settings give high resolution

p1<-ggplot(plot.dat1,aes(x=Genotype,y=Mean,group=Trisomy,colour= Trisomy))+geom_line()+geom_point(aes(shape = Trisomy))+geom_errorbar(aes(ymin=Mean-SE, ymax=Mean+SE), width=.2,
                 position=position_dodge(0.1))+facet_grid(SNP~phenotype)+theme_bw()+theme(legend.position="bottom",text = element_text(size=12),
  strip.text.y = element_blank())+ scale_x_continuous(breaks=seq(0,2,1))+xlab(" ")

p2<-ggplot(plot.dat2,aes(x=Genotype,y=Mean,group=Trisomy,colour= Trisomy))+geom_line()+geom_point(aes(shape = Trisomy))+geom_errorbar(aes(ymin=Mean-SE, ymax=Mean+SE), width=.2,
                 position=position_dodge(0.1))+facet_grid(SNP~phenotype)+theme_bw()+theme(legend.position="bottom",text = element_text(size=12),
  strip.text.y = element_blank(),axis.title.y=element_blank())+ scale_x_continuous(breaks=seq(0,2,1))+xlab("N. minor alleles")

p3<-ggplot(plot.dat3,aes(x=Genotype,y=Mean,group=Trisomy,colour= Trisomy))+geom_line()+geom_point(aes(shape = Trisomy))+geom_errorbar(aes(ymin=Mean-SE, ymax=Mean+SE), width=.2,
                 position=position_dodge(0.1))+facet_grid(SNP~phenotype)+theme_bw()+theme(legend.position="bottom",text = element_text(size=12),axis.title.y=element_blank())+ scale_x_continuous(breaks=seq(0,2,1))+xlab(" ")

grid.arrange(p1, p2, p3, nrow = 1)

grid_arrange_shared_legend <- function(..., ncol = length(list(...)), nrow = 1, position = c("bottom", "right")) {

  plots <- list(...)
  position <- match.arg(position)
  g <- ggplotGrob(plots[[1]] + theme(legend.position = position))$grobs
  legend <- g[[which(sapply(g, function(x) x$name) == "guide-box")]]
  lheight <- sum(legend$height)
  lwidth <- sum(legend$width)
  gl <- lapply(plots, function(x) x + theme(legend.position="none"))
  gl <- c(gl, ncol = ncol, nrow = nrow)

  combined <- switch(position,
                     "bottom" = arrangeGrob(do.call(arrangeGrob, gl),
                                            legend,
                                            ncol = 1,
                                            heights = unit.c(unit(1, "npc") - lheight, lheight)),
                     "right" = arrangeGrob(do.call(arrangeGrob, gl),
                                           legend,
                                           ncol = 2,
                                           widths = unit.c(unit(1, "npc") - lwidth, lwidth)))

  grid.newpage()
  grid.draw(combined)

  # return gtable invisibly
  invisible(combined)

}

grid_arrange_shared_legend(p3, p1, p2, nrow = 1)
dev.off() #stop sending output to png

```

```{R write data, echo=FALSE}
#Write the original data to a csv file after removing IDs
#Also remove data on schooling, slt and pre-postnatal diag for confidentiality
#NB This file is pseudanonymised because individual rare SNP can identify unique individual
#Therefore this file cannot be made fully open - we reported synthesised data and covar matrix (see below)

all.data$ID <-1:500
all.data$record_id <-1:500
short.data<- all.data[,-c(69,71,86)]
write.csv(all.data,'genopheno_data_sct_twin.csv')
```

```{R simulatedata, echo=FALSE}
#create simulated dataset with same characteristics

#SCT cases: synthesise from whole dataset with trisomy/bias as predictors.
all.data$bias<-NA
w <- which(all.data$why_tested==3)
all.data$bias[w] <-1
w <- which(all.data$why_tested!=3)
all.data$bias[w] <-0

simvars <- c(86,92,2:48,58,88:89) #trisomy, bias, all SNPS, then 3 phenos
sct.all <-all.data[1:130,simvars]
syn.all <-syn(sct.all) #NB this creates a list; we need $syn part
compare.synds(syn.all,sct.all) #compare function only works prior to unlisting
#This shows the frequencies of different values in original and synthesised data
syn.data <-syn.all$syn #just the synthesised data
rsyn<-cor(as.matrix(syn.data))
rsct<-cor(sct.all)
rdiff<-rsct-rsyn #differences between real and synthetised correlations
hist(rdiff,breaks=20,main='Difference between real/synthesised dataset: correlations')  

names <- c(1:49) #columns to convert to factors
syn.data[,names] <- lapply(syn.data[,names] , factor) #factors give more succinct summary output
summary(syn.data)

```


##Session information
```{r sessinfo}
sessionInfo()
```
